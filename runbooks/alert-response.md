# Alert Response Runbook

## Scope
Covers production alerts generated by observability pipelines (synthetic probes, SLO breaches, supply-chain scans).

## Alert Sources & Owners
- **Synthetic probes** (`synthetics:*` Nx targets) → SRE primary; escalate to respective service owner if failing >2 runs.
- **SLO breaches** (Grafana alerts referencing `dashboards/*.json`) → Feature team owning the impacted service.
- **Supply-chain findings** (`observability-quality` workflow) → Security & Compliance shared channel.

## Response Workflow
1. **Acknowledge** in incident tooling (PagerDuty ticket). Include runbook link.
2. **Collect evidence**:
   - `dist/reports/*.json` from latest CI run.
   - OTLP trace samples filtered by `tenant.id` and `data.residency`.
   - Relevant log slices from pino output.
3. **Mitigate** based on condition:
   - *Synthetic failure*: Trigger redeploy of impacted service or disable experiment via feature flag if false positive. Use `runbooks/chaos-drills.md` for context if failure occurred during chaos event.
   - *SLO breach*: Follow rollback criteria in `docs/OBSERVABILITY_TESTING.md`. Execute automated rollback pipeline if thresholds exceeded.
   - *Supply-chain finding*: Quarantine artifact, open ticket referencing `artifacts/grype.json` or `artifacts/trivy.json`, and block release.
4. **Communicate** updates in #incident channel every 15 minutes until resolved.
5. **Close** incident once metrics stable for two consecutive alert windows; attach evidence to ticket.

## Automation Hooks
- GitHub Actions automatically uploads artifacts; link them in the incident timeline.
- `pnpm nx run chaos:validate` ensures experiment manifests remained unchanged during investigation.

## Post-Incident Checklist
- Update affected SLO dashboards if thresholds adjusted.
- Amend telemetry configuration (redaction lists, span attributes) if root cause tied to missing context.
- Document learnings in `CHANGELOG.md` or relevant ADR.
